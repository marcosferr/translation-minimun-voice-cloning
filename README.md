
# Translation Pipeline with Voice Cloning

> Fully automated video translation with voice cloning.  
> Inspired by how Meta translates Reels at scale.  
> **Only 5 seconds of voice required.**

This repository provides a **minimal, end-to-end pipeline** for translating videos while **preserving the original speakerâ€™s voice**, using modern speech-to-text, translation, and TTS models.

The main goal is to make **high-quality English technical content accessible to Spanish-speaking audiences** (and other languages) with **minimal setup and zero manual steps**.

---

## âœ¨ Why this project?

Most valuable technical content is published in English.  
Language should not be the limiting factor for learning.

This project demonstrates how modern AI tooling can reduce that barrier **without sacrificing speaker identity**, using an approach similar to large-scale localization systems used by platforms like **Meta**.

---

## ğŸ”‘ Key Features

- âœ… Fully automated pipeline (no manual editing)
- ğŸ™ Voice cloning with **only 3â€“10 seconds of clean audio**
- ğŸ§© Segment-by-segment translation optimized for lip-sync
- âš™ï¸ Simple, reproducible setup
- ğŸ§ª Designed to be extended or integrated into larger workflows

---

## ğŸ§  Pipeline Overview



FFmpeg â†’ Whisper API â†’ GPT-5 mini â†’ Chatterbox TTS â†’ FFmpeg

````

| Step | Description |
|-----|------------|
| FFmpeg | Extracts and merges audio/video |
| Whisper API | Transcribes audio with timestamps |
| GPT-5 mini | Translates segments individually |
| Chatterbox TTS | Generates cloned voice |
| FFmpeg | Assembles final translated video |

---

## ğŸš€ Quick Start

### Requirements

- **Python 3.10+**
- **FFmpeg** (installed and in PATH)
- Optional: CUDA-capable GPU (CPU works, slower)

Verify FFmpeg:
```bash
ffmpeg -version
````

---

### Installation

```bash
git clone https://github.com/marcosferr/translation-minimun-voice-cloning.git
cd translation-minimun-voice-cloning

python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

pip install -r requirements.txt
```

---

### OpenAI API Key

Create a `.env` file:

```bash
cp .env.example .env
```

Add your key:

```env
OPENAI_API_KEY=sk-your-actual-api-key-here
```

---

## â–¶ï¸ Usage

### Basic example

```bash
python translate.py input.mp4 voice.wav output.mp4
```

### Custom languages

```bash
python translate.py input.mp4 voice.wav output.mp4 \
  --source-lang en \
  --target-lang es
```

### Force CPU

```bash
python translate.py input.mp4 voice.wav output.mp4 --device cpu
```

---

## ğŸ“¥ Input Requirements

### Video

* Format: MP4, AVI, MOV (FFmpeg compatible)
* Audio extracted automatically

### Voice Prompt

* Format: WAV (recommended)
* Duration: **3â€“10 seconds**
* Clean audio, single speaker, no background noise

---

## ğŸŒ Supported Languages

| Language   | Code |
| ---------- | ---- |
| Spanish    | es   |
| English    | en   |
| French     | fr   |
| German     | de   |
| Italian    | it   |
| Portuguese | pt   |
| Japanese   | ja   |
| Korean     | ko   |
| Chinese    | zh   |

Full list:
[https://platform.openai.com/docs/guides/speech-to-text/supported-languages](https://platform.openai.com/docs/guides/speech-to-text/supported-languages)

---

## ğŸ§ª Reproducible Test Setup

* OS: Windows
* Python: 3.11
* GPU tested: NVIDIA RTX 4060 (CUDA 12.4)

Example:

```bash
conda create -n tts-env python=3.11 -y
conda activate tts-env
conda install -c conda-forge ffmpeg numpy<1.26 pysoundfile -y
pip install -r requirements.txt
pip install chatterbox-tts python-dotenv openai
```

---

## âš ï¸ Current Limitations

This minimal implementation does **not** handle:

* Time-stretching to match original segment duration
* Silence preservation
* Retry logic
* Batch/queue processing
* Manual post-editing

---

## ğŸ›£ Roadmap / Next Steps

* â± Time-stretching for better sync
* ğŸ”‡ Silence preservation
* ğŸ§± Modular pipeline stages
* ğŸ§ª CLI improvements (progress, verbose mode)
* ğŸ‘„ Wav2Lip integration for lip-sync

---

## ğŸ™Œ Credits

Video reference used for testing:
**Stephane Maarek â€” Amazon GuardDuty Deep Dive**

---

## ğŸ“„ License

MIT License â€” free to use, modify, and extend.


